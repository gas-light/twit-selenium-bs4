{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Twitter Advanced Search using Selenium and BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "import urllib.request\n",
    "import requests\n",
    "import re\n",
    "from IPython import embed\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import StaleElementReferenceException"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create functions for scraping tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keyword scraping approach, combined use of selenium and beautiful soup\n",
    "\n",
    "#twit_url function will return correct url to target\n",
    "\n",
    "#notes on expected format of inputs, strings\n",
    "#date format: YYYY-MM-DD\n",
    "#loc: Manila, Cebu, Davao\n",
    "#radius: 150mi or 100mi\n",
    "#function will read keyword as hashtag automatically (in respect of Twitter robots.txt file)\n",
    "\n",
    "def twit_url(keyword,beg_date,end_date,loc,radius):\n",
    "    targeting=\"http://twitter.com/search?q=%23\" + keyword + \"%20near%3A\" + loc + \"%20within%3A\" + radius + \"%20until%3A\" + end_date +\"%20since%3A\"+ beg_date + \"&f=live\"\n",
    "    return targeting\n",
    "\n",
    "#trying to get all html content of twitter search page\n",
    "\n",
    "#manual crawl function tries to collect all page info as you scroll down\n",
    "#manual because we set number of scrolls\n",
    "#limited by number of scrolls set, might not be end of page yet if set too low, say, below 100\n",
    "\n",
    "def manual_crawl_page(url,n):\n",
    "    #loading search page\n",
    "    driver=webdriver.Chrome()\n",
    "    driver.get(url)\n",
    "    driver.implicitly_wait(15)\n",
    "    \n",
    "    #empty list where we will append all html content collected as we scroll down\n",
    "    html=[]\n",
    "    \n",
    "    #scroll for n seconds\n",
    "    for i in range(n):\n",
    "        #search for all relevant contents of twitter search page\n",
    "        list_items = driver.find_elements_by_class_name('css-1dbjc4n')\n",
    "        #collecting html content\n",
    "        html.append(list_items[0].get_attribute('innerHTML'))\n",
    "        \n",
    "        #to scroll down\n",
    "        elem = driver.find_element_by_tag_name('body')\n",
    "        elem.send_keys(Keys.END)\n",
    "        \n",
    "        time.sleep(np.random.randint(1,3))\n",
    "    \n",
    "    #parsing each html content collected\n",
    "    soup=[]\n",
    "    for i in html:    \n",
    "        soup += BeautifulSoup(i,'lxml')\n",
    "        \n",
    "    return soup\n",
    "\n",
    "#auto crawl function tries to collect all page info as it automatically scrolls down until end of page\n",
    "#note: takes some time to finish, also extracts fewer tweets. might be due to pace of scrolling\n",
    "\n",
    "def auto_crawl_page(url):\n",
    "    #loading search page\n",
    "    driver=webdriver.Chrome()\n",
    "    driver.get(url)    \n",
    "    \n",
    "    time.sleep(np.random.randint(1,3))  \n",
    "    \n",
    "    #empty list where we will append all html content collected as we scroll down\n",
    "    html=[]\n",
    "    \n",
    "    #calculates length of page\n",
    "    lenpage = driver.execute_script(\"var lenpage=document.body.scrollHeight;return lenpage;\")      \n",
    "    \n",
    "    #to iterate until bottom of page\n",
    "    match=False\n",
    "    while(match==False):\n",
    "        #implicitly wait to load page\n",
    "        driver.implicitly_wait(10)\n",
    "        \n",
    "        #search for all relevant contents of twitter search page\n",
    "        list_items = driver.find_elements_by_class_name('css-1dbjc4n')\n",
    "        #collecting html content\n",
    "        html.append(list_items[0].get_attribute('innerHTML'))\n",
    "        \n",
    "        #re-assigns value of length of page\n",
    "        lastcount = lenpage\n",
    "        \n",
    "        time.sleep(np.random.randint(10,30))\n",
    "        \n",
    "        #to scroll down\n",
    "        elem = driver.find_element_by_tag_name('body')\n",
    "        elem.send_keys(Keys.END)\n",
    "        \n",
    "        #re-calculates length of page\n",
    "        lenpage = driver.execute_script(\"var lenpage=document.body.scrollHeight;return lenpage;\")\n",
    "        \n",
    "        #criteria that evaluates if we are at the bottom of page already\n",
    "        if lastcount==lenpage:\n",
    "            match=True\n",
    "    \n",
    "    #parsing each html content collected\n",
    "    soup=[]\n",
    "    for i in html:    \n",
    "        soup += BeautifulSoup(i,'lxml')\n",
    "        \n",
    "    return soup\n",
    "\n",
    "\n",
    "#function extracting tweet details\n",
    "\n",
    "def twitsrc_data(soup):\n",
    "    #get all tweets from each parsed html\n",
    "    tweets=[]\n",
    "    for a in soup:\n",
    "        temp=a.find_all('article')\n",
    "        for b in temp:\n",
    "            tweets.append(b)\n",
    "    \n",
    "    #empty lists where we will append tweet info\n",
    "    post=[]\n",
    "    timestamp=[]\n",
    "    retweet=[]\n",
    "    like=[]\n",
    "    reply=[]\n",
    "\n",
    "    #to iterate over tweets collected, if-else is to account for unexpected errors\n",
    "    for i in tweets:\n",
    "        #post\n",
    "        post.append(re.sub('(.*)\\@(\\w+)\\W\\d+h?\\s?(Mar|Apr|May)?','',i.get_text())) #post\n",
    "        \n",
    "        #timestamp\n",
    "        if i.find('time')==None:\n",
    "            timestamp.append(np.nan)\n",
    "        elif len(i.find('time')['datetime'])==19:\n",
    "            timestamp.append(i.find('time')['datetime'])\n",
    "        elif len(i.find('time')['datetime'])==24:\n",
    "            timestamp.append(i.find('time')['datetime'].replace('.000Z',''))\n",
    "        \n",
    "        #retweets\n",
    "        if i.find('div',{'data-testid':'retweet'})==None:\n",
    "            retweet.append(0)\n",
    "        else:\n",
    "            retweet.append(i.find('div',{'data-testid':'retweet'}).get_text()) #retweet\n",
    "        \n",
    "        #likes\n",
    "        if i.find('div',{'data-testid':'like'})==None:\n",
    "            like.append(0)\n",
    "        else:\n",
    "            like.append(i.find('div',{'data-testid':'like'}).get_text())#like\n",
    "        \n",
    "        #replies\n",
    "        if i.find('div',{'data-testid':'reply'})==None:\n",
    "            reply.append(0)\n",
    "        else:\n",
    "            reply.append(i.find('div',{'data-testid':'reply'}).get_text()) #reply\n",
    "    \n",
    "    #making dataframe of all tweet info\n",
    "    df=pd.DataFrame({'timestamp':timestamp,'post':post,'reply':reply,'like':like,'retweet':retweet})\n",
    "    \n",
    "    #some tweets don't have necessary tag for tweet stats so it returns blanks, replacing them with 0\n",
    "    df['reply']=df['reply'].replace('',0)\n",
    "    df['like']=df['like'].replace('',0)\n",
    "    df['retweet']=df['retweet'].replace('',0)\n",
    "    \n",
    "    #drop duplicate tweets which may be collected repeatedly due to overlaps in page info while scrolling\n",
    "    df=df.drop_duplicates(subset=['timestamp', 'post', 'reply', 'like', 'retweet'],keep='first')\n",
    "    \n",
    "    #making sure indices are in order\n",
    "    df=df.reset_index()\n",
    "    df=df.drop(columns='index')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>post</th>\n",
       "      <th>reply</th>\n",
       "      <th>like</th>\n",
       "      <th>retweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-03-16T23:58:58</td>\n",
       "      <td>Before #COVID19PH struck this 2020, the govern...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>RedDeerGames@GamesRedDeerDid You see it? \\nhtt...</td>\n",
       "      <td>9</td>\n",
       "      <td>247</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-16T23:58:21</td>\n",
       "      <td>Starbucks Philippines to suspend operations in...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-03-16T23:56:00</td>\n",
       "      <td>A crisis exposes what you already are.\\n\\nHow ...</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-03-16T22:13:08</td>\n",
       "      <td>Stuck in the city we're in. Feels like the mov...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>2020-03-16T00:02:44</td>\n",
       "      <td>Avoid crowded people. Observe social distancin...</td>\n",
       "      <td>7</td>\n",
       "      <td>2K</td>\n",
       "      <td>1.1K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>2020-03-16T00:02:44</td>\n",
       "      <td>Avoid crowded people. Observe social distancin...</td>\n",
       "      <td>7</td>\n",
       "      <td>2K</td>\n",
       "      <td>1.1K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>2020-03-16T00:02:44</td>\n",
       "      <td>Avoid crowded people. Observe social distancin...</td>\n",
       "      <td>7</td>\n",
       "      <td>2K</td>\n",
       "      <td>1.1K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>2020-03-16T00:02:44</td>\n",
       "      <td>Avoid crowded people. Observe social distancin...</td>\n",
       "      <td>7</td>\n",
       "      <td>2K</td>\n",
       "      <td>1.1K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>2020-03-16T00:02:44</td>\n",
       "      <td>Avoid crowded people. Observe social distancin...</td>\n",
       "      <td>7</td>\n",
       "      <td>2K</td>\n",
       "      <td>1.1K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>141 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               timestamp                                               post  \\\n",
       "0    2020-03-16T23:58:58  Before #COVID19PH struck this 2020, the govern...   \n",
       "1                    NaN  RedDeerGames@GamesRedDeerDid You see it? \\nhtt...   \n",
       "2    2020-03-16T23:58:21  Starbucks Philippines to suspend operations in...   \n",
       "3    2020-03-16T23:56:00  A crisis exposes what you already are.\\n\\nHow ...   \n",
       "4    2020-03-16T22:13:08  Stuck in the city we're in. Feels like the mov...   \n",
       "..                   ...                                                ...   \n",
       "136  2020-03-16T00:02:44  Avoid crowded people. Observe social distancin...   \n",
       "137  2020-03-16T00:02:44  Avoid crowded people. Observe social distancin...   \n",
       "138  2020-03-16T00:02:44  Avoid crowded people. Observe social distancin...   \n",
       "139  2020-03-16T00:02:44  Avoid crowded people. Observe social distancin...   \n",
       "140  2020-03-16T00:02:44  Avoid crowded people. Observe social distancin...   \n",
       "\n",
       "    reply like retweet  \n",
       "0       1    0       0  \n",
       "1       9  247      97  \n",
       "2       1    5       3  \n",
       "3       1   11       4  \n",
       "4       0    1       0  \n",
       "..    ...  ...     ...  \n",
       "136     7   2K    1.1K  \n",
       "137     7   2K    1.1K  \n",
       "138     7   2K    1.1K  \n",
       "139     7   2K    1.1K  \n",
       "140     7   2K    1.1K  \n",
       "\n",
       "[141 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_url = twit_url('covid19ph','2020-03-16','2020-03-17', 'Manila', '150mi')\n",
    "sample_soup = manual_crawl_page(sample_url,50)\n",
    "\n",
    "twitsrc_data(sample_soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = twit_url('covid19ph','2020-03-16','2020-05-15', 'Manila', '150mi')\n",
    "soup = manual_crawl_page(url, 1000)\n",
    "data = twitsrc_data(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1738, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>post</th>\n",
       "      <th>reply</th>\n",
       "      <th>like</th>\n",
       "      <th>retweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-05-14T14:47:34</td>\n",
       "      <td>Bago magresume ang klase sa lahat ng antas, mg...</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Alex Walton@WildcardWaltonThe Marvel Nexus War...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-05-14T10:20:50</td>\n",
       "      <td>Handa napo ba talaga tayo??? \\n\\nMap of Active...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-05-14T09:42:22</td>\n",
       "      <td>World #COVID19 status May 14 2020.\\n\\n#Philipp...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-05-14T08:44:25</td>\n",
       "      <td>@BacoorCityGovt @DILGPhilippines @pcoogov #PHG...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp                                               post  \\\n",
       "0  2020-05-14T14:47:34  Bago magresume ang klase sa lahat ng antas, mg...   \n",
       "1                  NaN  Alex Walton@WildcardWaltonThe Marvel Nexus War...   \n",
       "2  2020-05-14T10:20:50  Handa napo ba talaga tayo??? \\n\\nMap of Active...   \n",
       "3  2020-05-14T09:42:22  World #COVID19 status May 14 2020.\\n\\n#Philipp...   \n",
       "4  2020-05-14T08:44:25  @BacoorCityGovt @DILGPhilippines @pcoogov #PHG...   \n",
       "\n",
       "  reply like retweet  \n",
       "0     2   11       4  \n",
       "1     0    0       0  \n",
       "2     0    0       0  \n",
       "3     0    0       0  \n",
       "4     0    0       0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Clean scraped Twitter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove irrelevant records\n",
    "data=data[~data['timestamp'].isnull()]\n",
    "\n",
    "#prettify indices\n",
    "data=data.reset_index()\n",
    "data=data.drop(columns='index')\n",
    "\n",
    "\n",
    "#fixing timestamps and making new date and time columns\n",
    "data['timestamp']=data['timestamp'].apply(str)\n",
    "data['date']=pd.to_datetime(data['timestamp'].apply(lambda x: x.split('T')[0])).dt.date\n",
    "data['time']=pd.to_datetime(data['timestamp'].apply(lambda x: x[11:])).dt.time\n",
    "data['timestamp']=data['date'].apply(str) + \" \" + data['time'].apply(str)\n",
    "data['timestamp']=pd.to_datetime(data['timestamp'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "\n",
    "#cleaning post content\n",
    "data['post']=data['post'].str.replace('\\n',' ')\n",
    "\n",
    "\n",
    "#to fix likes and retweets, removes K-- which indicates thousand values\n",
    "def kLikes(row):\n",
    "    if row['like'] == None:\n",
    "        row['like'] = '0'\n",
    "    if 'K' in row['like']:\n",
    "        digits = re.findall('\\d+', row['like'])\n",
    "        if len(digits) == 1:\n",
    "            return digits[0] + '000'\n",
    "        elif len(digits) == 2:\n",
    "            return digits[0] + digits[1] +'00'\n",
    "    else:\n",
    "        return row['like']\n",
    "\n",
    "def kRetweets(row):\n",
    "    if row['retweet'] == None:\n",
    "        row['retweet'] = '0'\n",
    "    if 'K' in row['retweet']:\n",
    "        digits = re.findall('\\d+', row['retweet'])\n",
    "        if len(digits) == 1:\n",
    "            return digits[0] + '000'\n",
    "        elif len(digits) == 2:\n",
    "            return digits[0] + digits[1] +'00'\n",
    "    else:\n",
    "        return row['retweet']\n",
    "\n",
    "data['like'] = data['like'].astype('str')\n",
    "data['retweet'] = data['retweet'].astype('str')\n",
    "data['like'] =data.apply(kLikes, axis = 1)\n",
    "data['retweet'] = data.apply(kRetweets, axis = 1)\n",
    "data['like'] = data['like'].astype('int64')\n",
    "data['retweet'] = data['retweet'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1731, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>post</th>\n",
       "      <th>reply</th>\n",
       "      <th>like</th>\n",
       "      <th>retweet</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-05-14 14:47:34</td>\n",
       "      <td>Bago magresume ang klase sa lahat ng antas, mg...</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-14</td>\n",
       "      <td>14:47:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-05-14 10:20:50</td>\n",
       "      <td>Handa napo ba talaga tayo???   Map of Active C...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-14</td>\n",
       "      <td>10:20:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-05-14 09:42:22</td>\n",
       "      <td>World #COVID19 status May 14 2020.  #Philippin...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-14</td>\n",
       "      <td>09:42:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-05-14 08:44:25</td>\n",
       "      <td>@BacoorCityGovt @DILGPhilippines @pcoogov #PHG...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-14</td>\n",
       "      <td>08:44:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-05-13 11:07:53</td>\n",
       "      <td>World #COVID19 status May 13 2020.  #Philippin...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-13</td>\n",
       "      <td>11:07:53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp                                               post  \\\n",
       "0 2020-05-14 14:47:34  Bago magresume ang klase sa lahat ng antas, mg...   \n",
       "1 2020-05-14 10:20:50  Handa napo ba talaga tayo???   Map of Active C...   \n",
       "2 2020-05-14 09:42:22  World #COVID19 status May 14 2020.  #Philippin...   \n",
       "3 2020-05-14 08:44:25  @BacoorCityGovt @DILGPhilippines @pcoogov #PHG...   \n",
       "4 2020-05-13 11:07:53  World #COVID19 status May 13 2020.  #Philippin...   \n",
       "\n",
       "  reply  like  retweet        date      time  \n",
       "0     2    11        4  2020-05-14  14:47:34  \n",
       "1     0     0        0  2020-05-14  10:20:50  \n",
       "2     0     0        0  2020-05-14  09:42:22  \n",
       "3     0     0        0  2020-05-14  08:44:25  \n",
       "4     1     0        0  2020-05-13  11:07:53  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
